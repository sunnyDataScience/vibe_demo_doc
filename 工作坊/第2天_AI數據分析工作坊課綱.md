# AI Vibe Coding 工作坊：數據分析實戰
## 第二天課程 - 從概念到實作的數據分析之旅

> **課程定位**：透過 AI 協作完成數據分析，重概念輕程式碼
> **時長**：6 小時
> **目標學員**：零程式基礎但想學數據分析者

---

## 📋 課程模組總覽（調整版：70%實作、30%講解）

### ⏰ 時間配置原則
```
【避免聽課地獄的設計】
- 每個模組：10分鐘講解 → 20分鐘實作 → 5分鐘總結
- 講師Demo → 學生跟著做 → 自己練習 → 分享討論
- 每小時至少40分鐘在動手，不是在聽課
```

| 時段 | 模組 | 講解/實作 | 內容重點 | 實作任務 |
|:-----|:-----|:---------|:---------|:---------|
| **09:00-09:20** | 開場 | 講15/做5 | • 為什麼學Python<br>• 展示今天成果 | 環境測試 |
| **09:20-10:00** | 基礎實作 | 講10/做30 | • Python基本語法<br>• 用Supermarket數據 | 載入第一個數據 |
| **10:00-10:15** | 休息 | - | 茶點時間 | - |
| **10:15-11:00** | Pandas入門 | 講10/做35 | • DataFrame操作<br>• 篩選與分組 | 銷售Top10分析 |
| **11:00-12:00** | 數據清洗 | 講15/做45 | • 處理缺失值<br>• 資料轉換 | 清理髒數據挑戰 |
| **12:00-13:00** | 午餐 | - | 午餐休息 | - |
| **13:00-14:00** | 視覺化 | 講10/做50 | • 5種必學圖表<br>• 用Matplotlib | 製作銷售儀表板 |
| **14:00-14:15** | 休息 | - | 茶點時間 | - |
| **14:15-15:15** | 大數據RFM | 講15/做45 | • 切換54萬筆數據<br>• RFM分析 | 客戶分群實戰 |
| **15:15-16:15** | AI加速 | 講10/做50 | • Prompt技巧<br>• ChatGPT協作 | 用AI完成分析 |
| **16:15-17:00** | 成果發表 | 講5/做40 | • Streamlit部署<br>• 作品分享 | 3分鐘Demo |
| **17:00-17:30** | 總結 | 講20/做10 | • 回顧與展望<br>• 資源分享 | Q&A交流 |

### 📊 時間統計
- **總時長**：8.5小時（含休息）
- **實際上課**：6小時
- **講解時間**：約2小時（33%）
- **實作時間**：約4小時（67%）
- **休息時間**：2.5小時

## 🎯 防止聽課地獄的教學節奏設計

### 每個時段的微節奏（以Pandas入門為例）
```
【10:15-11:00 Pandas入門（45分鐘）】

10:15-10:20（5分鐘）- 快速概念
- 講師：「DataFrame就像Excel表格」
- 展示：一個簡單範例
- 目標：理解是什麼，不是怎麼做

10:20-10:25（5分鐘）- 跟著做
- 講師：Live Coding載入數據
- 學生：照著打一遍
- 助教：巡視協助

10:25-10:35（10分鐘）- 第一個練習
- 任務：「找出銷售額前5名的產品」
- Prompt模板提供
- 鼓勵先試錯，再看答案

10:35-10:45（10分鐘）- 第二個練習
- 任務：「計算每個分店的總銷售」
- 難度提升一點
- 可以問AI或同學

10:45-10:55（10分鐘）- 小組分享
- 2-3位學生分享做法
- 講師點評不同解法
- 強調：沒有標準答案

10:55-11:00（5分鐘）- 收尾總結
- 重點回顧（不是重講）
- 預告下一段
- 激勵：「你已經會分析數據了！」
```

### 關鍵教學技巧
```
【避免無聊的方法】
1. 倒數計時器
   - 每個練習設定時間
   - 營造緊張感和遊戲感

2. 即時投票
   - 用Mentimeter問：「完成了嗎？」
   - 讓學生有參與感

3. 錯誤慶祝
   - 「誰遇到錯誤？舉手！」
   - 「錯誤是最好的老師」
   - 一起debug更有趣

4. Peer Learning
   - 完成的幫還沒完成的
   - 建立互助氛圍

5. 成就解鎖
   - 完成一個任務就打勾
   - 視覺化進度條
   - 小獎勵（貼紙、糖果）
```

### 講師話術範例
```
❌ 錯誤示範：
「接下來我要講30分鐘的Pandas理論...」

✅ 正確示範：
「給你們5分鐘，用這個Prompt試試看能不能找出最賺錢的產品！」
「卡住了？很好！讓AI幫你！」
「哇，你用了不同方法，分享一下！」
```

## 📝 各時段具體練習題設計

### 09:20-10:00 基礎實作練習
```
【練習1：Hello Data（10分鐘）】
任務：載入Supermarket銷售數據
Prompt：「幫我用pandas讀取supermarket_sales.csv」
成功標準：看到前5筆數據

【練習2：我的第一個分析（10分鐘）】
任務：計算總銷售額
Prompt：「計算Total欄位的總和」
成功標準：得出一個數字

【練習3：簡單篩選（10分鐘）】
任務：找出所有女性客戶的購買記錄
Prompt：「篩選Gender欄位為Female的資料」
成功標準：顯示篩選結果
```

### 10:15-11:00 Pandas實戰練習
```
【練習1：Top 10產品（15分鐘）】
任務：找出銷售額最高的10個產品線
Prompt模板：「請按[Product line]分組，計算[Total]的總和，並排序顯示前10名」
挑戰加分：加上視覺化長條圖

【練習2：分店比較（15分鐘）】
任務：比較ABC三家分店的業績
Prompt模板：「按[Branch]分組，計算各項指標」
挑戰加分：計算平均客單價
```

### 11:00-12:00 數據清洗練習
```
【練習1：髒數據挑戰（20分鐘）】
任務：處理一份有問題的數據（講師準備）
- 有空值
- 有重複
- 格式不一致
Prompt：「檢查並清理這份數據的品質問題」

【練習2：數據轉換（20分鐘）】
任務：創建新欄位
- 計算毛利率
- 提取月份
- 分類客戶等級
Prompt：「幫我創建[描述]的新欄位」
```

### 13:00-14:00 視覺化練習
```
【練習1：銷售儀表板（25分鐘）】
任務：製作4個圖表
1. 月銷售趨勢（折線圖）
2. 產品線佔比（圓餅圖）
3. 分店業績（長條圖）
4. 付款方式分析（堆疊圖）

【練習2：互動圖表（20分鐘）】
任務：用Plotly做一個可互動的圖表
Prompt：「用plotly製作可以hover顯示詳細資訊的圖表」
```

### 14:15-15:15 RFM大數據練習
```
【練習1：處理54萬筆（20分鐘）】
任務：不要怕！載入大數據
步驟：
1. 先載入1萬筆測試
2. 確認程式碼正確
3. 載入全部數據
Prompt：「幫我載入online_retail.csv並顯示數據規模」

【練習2：RFM計算（20分鐘）】
任務：計算每個客戶的RFM值
Prompt：「計算客戶的Recency、Frequency、Monetary」
成就感：處理54萬筆只要幾秒！
```

### 15:15-16:15 AI協作練習
```
【練習1：一鍵分析（20分鐘）】
任務：用一個Prompt完成複雜分析
挑戰：「幫我做完整的RFM客戶分群分析，包含分群、視覺化、策略建議」

【練習2：Debug練習（20分鐘）】
任務：故意寫錯，讓AI幫忙改
學習：如何描述錯誤給AI

【練習3：優化程式（10分鐘）】
任務：讓AI改進你的程式碼
Prompt：「優化這段程式碼的效能和可讀性」
```

### 16:15-17:00 成果展示準備
```
【最終任務：3分鐘Demo準備】
1. 整理今天的分析成果
2. 準備3張投影片
   - 我學到了什麼
   - 我的分析發現
   - 我可以怎麼應用
3. 練習講解
4. 上台分享（自願）
```

### 📊 學習重點統計
- **總時長**：6小時（含休息）
- **模組數量**：10個模組
- **Prompt模板**：35個現成模板
- **核心工具**：Python、Pandas、SQL概念、Git/GitHub、IDE、Matplotlib、Seaborn、AI工具
- **產出成果**：完整數據分析報告 + Prompt模板庫 + 分析檢核清單 + GitHub作品集
- **新增內容**：
  * 開發環境設置（CMD vs IDE、虛擬環境）
  * 版本控制（Git/GitHub基礎操作）
  * 開發習慣（檔案命名、專案結構、除錯技巧）
  * 資料庫基礎（ER Model、主外鍵、JOIN、樞紐分析）
  * 麥肯錫七步分析法
  * 數據分析專案檢核清單
  * 數據分析師職涯發展路徑

### 🎓 學習路徑
```
概念理解 → 基礎語法 → 數據處理 → 品質控制 → 視覺呈現 → 分析思維 → AI協作 → 報告產出
```

---

## 🎯 課程核心理念

```
不是要教你成為程式高手
而是要讓你成為能與 AI 溝通的數據分析師
- 理解概念 > 背誦語法
- 知道有什麼工具 > 精通每個工具
- 會用 Prompt 驅動 > 自己寫程式碼
```

---

## 📂 資料集使用策略

### 資料集選擇與時機
```
【兩個層次的資料集】
1. 基礎教學資料集：Supermarket Sales（1,000筆）
   - 使用時機：Module 0-4（上午到下午2點）
   - 特色：乾淨、簡單、容易理解
   - 用途：學習基礎概念、練習語法、建立信心

2. 進階實戰資料集：Online Retail（54萬筆）
   - 使用時機：Module 5-7（下午3點後）
   - 特色：真實、複雜、大數據量
   - 用途：RFM分析、體驗Python處理大數據的威力

【為什麼這樣安排？】
- 降低學習曲線：從小數據開始，不會一開始就嚇到
- 建立成就感：快速看到結果，增加學習動力
- 展現Python優勢：處理54萬筆數據，Excel會當機但Python輕鬆搞定
```

## 📚 課程大綱

### Module 0：開場破冰與分析思維（30分鐘）09:00-09:30
📁 **資料集：尚未使用（純概念講解）**

#### 0-1 什麼是數據分析？為什麼重要？
```
【核心概念】
- 數據分析的定義：從數據中提取有價值的洞察
- 商業價值：降低成本、提升效率、發現機會
- 案例分享：
  * Netflix 如何用數據決定拍什麼劇
  * 7-11 如何用數據決定進什麼貨
  * Uber 如何用數據定價

【數據分析成熟度模型 - Gartner框架】
1. 描述性分析（Descriptive）- 發生了什麼？
   - 回答：What happened?
   - 工具：報表、儀表板、KPI
   - 價值：提供可見性（80%的企業分析工作）

2. 診斷性分析（Diagnostic）- 為什麼發生？
   - 回答：Why did it happen?
   - 工具：下鑽分析、根因分析、相關性分析
   - 價值：理解因果關係

3. 預測性分析（Predictive）- 將會發生什麼？
   - 回答：What is likely to happen?
   - 工具：機器學習、時間序列、統計建模
   - 價值：前瞻性決策

4. 規範性分析（Prescriptive）- 應該做什麼？
   - 回答：What should we do?
   - 工具：優化算法、模擬、決策樹
   - 價值：自動化決策

【探索性 vs 驗證性分析】
- 探索性分析（EDA）：開放式探索，發現模式
- 驗證性分析（CDA）：假設檢定，確認結論
```

#### 0-2 為什麼選 Python？工具生態系介紹
```
【Why Python】
- 最豐富的數據分析生態系
- AI 時代的主流語言
- 相對容易學習的語法

【核心工具地圖】
- 數據處理：Pandas（表格處理專家）
- 數值計算：NumPy（數學運算引擎）
- 視覺化：Matplotlib、Seaborn、Plotly（圖表製作）
- 統計分析：SciPy、Statsmodels（統計檢定）
- 機器學習：Scikit-learn（預測模型）

💡 重點：你不需要全部精通，知道它們存在就好
```

---

### Module 1：Python 基礎概念速成（45分鐘）09:30-10:15
📁 **資料集：簡單範例資料（自建5-10筆示範）**

#### 1-1 變數與資料類型（15分鐘）
```
【概念講解】
變數 = 容器（裝數據的盒子）
- 數字（int, float）：年齡、金額、數量
- 文字（string）：姓名、地址、產品名
- 布林（boolean）：是/否、有/無、真/假
- 列表（list）：多個數據的集合
- 字典（dict）：有標籤的數據集合

【Prompt 模板】
"請幫我創建變數來儲存 [數據描述]，
 例如 [具體例子]"

【範例 Prompt】
"請幫我創建變數儲存：
 - 客戶年齡（32歲）
 - 購買產品清單（手機、耳機、充電線）
 - 是否為VIP（是）"
```

#### 1-2 邏輯控制：條件判斷（15分鐘）
```
【概念講解】
如果...就...否則...（if-else）
- 商業邏輯的基礎
- 分類、篩選的核心

【應用場景】
- 客戶分級：消費金額 > 10000 → VIP
- 庫存警示：庫存 < 100 → 發出警告
- 折扣計算：購買數量 > 5 → 打9折

【Prompt 模板】
"請寫一個條件判斷：
 如果 [條件描述]，
 就 [動作1]，
 否則 [動作2]"
```

#### 1-3 迴圈：重複執行（15分鐘）
```
【概念講解】
對每個...都做...（for loop）
- 批次處理的基礎
- 自動化的關鍵

【應用場景】
- 計算每個產品的毛利率
- 發送郵件給每個客戶
- 處理每個月的銷售數據

【Prompt 模板】
"請用迴圈處理 [資料集合]，
 對每個 [項目] 執行 [動作]"
```

#### 1-4 函數：打包重複使用（15分鐘）
```
【概念講解】
函數 = 工具包
- 輸入 → 處理 → 輸出
- 一次定義，多次使用

【應用場景】
- 計算平均值的函數
- 清理數據的函數
- 產生報表的函數

【Prompt 模板】
"請創建一個函數，
 功能是 [描述]，
 輸入 [參數]，
 輸出 [結果]"
```

---

### Module 1.2：開發環境與工具基礎（15分鐘）10:15-10:30

#### 開發環境的選擇：為什麼這很重要？
```
【CMD（命令列） vs IDE 的差別】

命令列（CMD/Terminal）
- 是什麼：純文字介面，直接與電腦對話
- 為什麼學：
  * 雲端伺服器只有命令列
  * 自動化腳本需要用命令列執行
  * 許多工具只能在命令列使用
- 好處：
  * 輕量、快速
  * 可以批次處理
  * 遠端連線方便
- 實際應用："python analysis.py" 一行搞定

IDE（整合開發環境）
- 是什麼：像 Word 一樣的程式編輯器
- 常見選擇：
  * VS Code：免費、輕量、擴充多
  * PyCharm：Python 專用、功能強
  * Jupyter：數據分析首選、互動式
- 為什麼用：
  * 程式碼自動完成（不用背語法）
  * 即時錯誤提示（寫錯馬上知道）
  * 除錯工具（找問題更容易）
  * 整合終端機和版本控制
- 好處：
  * 降低入門門檻
  * 提高開發效率
  * 視覺化操作

【選擇建議】
初學者：Jupyter Notebook（互動學習）
日常分析：VS Code + Jupyter 擴充
大型專案：PyCharm Professional
雲端協作：Google Colab / Kaggle

【Prompt 模板】
"我要做[任務類型]，請推薦適合的開發環境和設定"
```

#### GitHub：程式碼的社交網路
```
【GitHub 是什麼？】
- 簡單說：程式碼的雲端硬碟 + 社交平台
- 核心功能：
  * 儲存程式碼（永遠不怕檔案遺失）
  * 版本控制（可以回到任何時間點）
  * 協作開發（多人同時改不會亂）
  * 展示作品（履歷的最佳證明）

【為什麼要學 GitHub？】
1. 求職必備
   - 企業看 GitHub 比看履歷重要
   - 展示你的真實能力
   - 證明持續學習

2. 學習資源
   - 看別人怎麼寫（開源專案）
   - 找現成工具（不用重造輪子）
   - 複製範例來改（站在巨人肩膀）

3. 備份保護
   - 電腦壞了程式還在
   - 寫錯了可以復原
   - 換電腦無縫接續

【基本操作（只需要會這些）】
1. Clone（下載）
   - 把別人的程式下載到電腦
   - "git clone [網址]"

2. Add + Commit（存檔）
   - 記錄你的修改
   - "git add ." → "git commit -m '修改說明'"

3. Push（上傳）
   - 把修改傳到雲端
   - "git push"

4. Pull（同步）
   - 把雲端最新版本拉下來
   - "git pull"

【實用場景】
- 分析專案：每天的分析都有記錄
- 團隊協作：看到誰改了什麼
- 學習筆記：把練習都存起來
- 作品集：給未來雇主看

【Prompt 模板】
"幫我生成 git 命令來[上傳/下載/版本回復]"
"解釋這個 git 錯誤訊息並告訴我如何修復"
```

#### 虛擬環境：為什麼要隔離？
```
【什麼是虛擬環境？】
- 簡單比喻：每個專案有自己的工具箱
- 避免問題：
  * A專案要pandas 1.0
  * B專案要pandas 2.0
  * 虛擬環境讓它們不打架

【為什麼要用？】
- 套件版本不衝突
- 專案可以完整移植
- 不會弄壞系統Python

【基本使用（只要會這個）】
創建："python -m venv myenv"
啟動："myenv\Scripts\activate"（Windows）
安裝："pip install pandas"
儲存："pip freeze > requirements.txt"

【Prompt 模板】
"幫我創建虛擬環境並安裝[專案類型]需要的套件"
```

#### 良好的開發習慣：從一開始就做對
```
【檔案命名規則】
好的命名：
✓ data_analysis_2024.py（清楚、有意義）
✓ customer_segmentation.ipynb（描述功能）
✓ 01_data_cleaning.py（有順序）

避免：
✗ test.py、test2.py、test_final.py
✗ 分析.py（避免中文檔名）
✗ my code.py（避免空格）

【專案結構：整齊才好找】
```
my_project/
├── data/          # 原始數據
│   ├── raw/       # 不要動的原始檔
│   └── processed/ # 處理後的檔案
├── notebooks/     # Jupyter筆記本
├── src/          # 程式碼
├── outputs/      # 結果輸出
├── README.md     # 專案說明
└── requirements.txt  # 套件清單
```

【註解習慣：未來的自己會感謝你】
好的註解：
- 解釋「為什麼」，而不是「什麼」
- 在複雜邏輯前加說明
- 記錄數據來源和假設

範例：
```python
# 使用對數轉換處理右偏分布
# 資料來源：2024年Q1銷售數據
df['log_sales'] = np.log1p(df['sales'])
```

【程式碼整潔】
- 一個函數只做一件事
- 變數名稱要有意義
- 避免重複程式碼（DRY原則）
- 適時重構（Refactor）

【錯誤處理：預期意外】
```python
# 好習慣：處理可能的錯誤
try:
    df = pd.read_csv('data.csv')
except FileNotFoundError:
    print("找不到檔案，請確認路徑")
    df = pd.DataFrame()  # 創建空的DataFrame
```

【版本控制習慣】
- 每個功能完成就commit
- commit訊息要清楚
- 不要把大檔案加入git
- 敏感資訊（密碼、API key）用環境變數

【測試思維】
- 寫完就測試
- 準備測試資料
- 邊界條件要考慮
- 保留測試程式碼

【Prompt 模板】
"幫我重構這段程式碼，遵循Python最佳實務"
"為這個專案生成標準的資料夾結構"
```

#### 除錯技巧：找問題的藝術
```
【常見錯誤類型】
1. SyntaxError（語法錯誤）
   - 通常是拼錯、少了冒號
   - IDE會直接標紅線

2. NameError（名稱錯誤）
   - 變數還沒定義就用
   - 拼錯變數名

3. TypeError（類型錯誤）
   - 對錯誤的資料類型操作
   - 例：字串加數字

4. KeyError（鍵值錯誤）
   - DataFrame欄位名稱錯誤
   - 字典的key不存在

【除錯步驟】
1. 讀錯誤訊息（通常已經告訴你答案）
2. Google錯誤訊息（別人都遇過）
3. print()大法（看變數內容）
4. 分段執行（找出哪一行出錯）
5. 請AI幫忙（貼錯誤訊息給AI）

【實用技巧】
- Jupyter：一格一格執行
- VS Code：設定中斷點
- print(type(x))：確認資料類型
- df.info()：檢查DataFrame結構
- df.head()：看前幾筆資料

【Prompt 模板】
"這是我的錯誤訊息：[錯誤]，程式碼是：[程式]，請幫我debug"
```

---

### Module 1.5：資料庫基礎知識（15分鐘）10:30-10:45

#### 資料庫核心概念
```
【關聯式資料庫基礎】

1. 實體關係模型（ER Model）
   - 實體（Entity）：真實世界的對象（如客戶、產品）
   - 屬性（Attribute）：實體的特徵（如客戶姓名、產品價格）
   - 關係（Relationship）：實體間的關聯
   - Prompt："請解釋這個資料集的實體關係結構"

2. 主鍵與外鍵（Primary Key & Foreign Key）
   - 主鍵（PK）：唯一識別每筆記錄的欄位
     * 例：客戶ID、訂單編號
     * 特性：唯一、非空
   - 外鍵（FK）：連結到其他表格主鍵的欄位
     * 例：訂單表中的客戶ID
     * 作用：維護參照完整性
   - Prompt："識別資料中的主鍵和外鍵關係"

3. SQL JOIN 操作概念
   - INNER JOIN：只保留兩表都有的記錄
   - LEFT JOIN：保留左表全部，右表匹配
   - RIGHT JOIN：保留右表全部，左表匹配
   - FULL OUTER JOIN：保留兩表全部記錄
   - Prompt："用pandas merge模擬SQL的[JOIN類型]操作"

4. 資料正規化（Normalization）
   - 第一正規化（1NF）：消除重複群組
   - 第二正規化（2NF）：消除部分相依
   - 第三正規化（3NF）：消除遞移相依
   - 目的：減少冗餘、維護一致性

5. 資料倉儲概念
   - 事實表（Fact Table）：記錄業務事件
   - 維度表（Dimension Table）：描述性資訊
   - 星狀架構（Star Schema）：一個事實表連接多個維度表
   - 雪花架構（Snowflake Schema）：維度表進一步正規化
```

#### 樞紐分析（Pivot）概念
```
【樞紐轉換的本質】
- 定義：將長格式數據轉換為寬格式的操作
- 目的：重新組織數據以便於分析和視覺化

【核心操作】
1. Pivot（樞紐）
   - 行轉列：將某欄位的值變成新的欄位
   - 例：將「月份」從列值變成欄位名稱
   - Prompt："將[欄位A]的值轉換為新的欄位"

2. Unpivot（反樞紐/Melt）
   - 列轉行：將多個欄位合併為一個欄位
   - 例：將12個月份欄位合併為一個「月份」欄位
   - Prompt："將寬格式數據轉換為長格式"

3. 交叉表（Cross-tabulation）
   - 計算兩個或更多因素的頻率分布
   - 類似Excel的樞紐分析表
   - Prompt："創建[維度1]和[維度2]的交叉分析表"

【應用場景】
- 銷售數據：產品×時間的銷售矩陣
- 用戶行為：用戶×功能的使用頻率
- 財務報表：科目×期間的金額分布
```

#### 資料流（Data Flow）概念
```
【資料處理管線】
1. ETL vs ELT
   - ETL：Extract → Transform → Load
   - ELT：Extract → Load → Transform
   - 選擇依據：資料量、處理能力、即時性需求

2. 資料流階段
   - 資料源（Source）：原始資料來源
   - 轉換（Transform）：清洗、聚合、計算
   - 目標（Target）：資料倉儲或分析工具

3. 資料品質控制點
   - 完整性檢查：主鍵、外鍵約束
   - 一致性檢查：業務規則驗證
   - 準確性檢查：數值範圍、格式驗證

【Prompt 模板】
"設計從[資料源]到[目標]的資料處理流程，
包含[清洗步驟]、[轉換邏輯]和[品質檢查]"
```

---

### Module 2：Pandas 數據處理核心（75分鐘）10:45-12:00
📁 **資料集：Supermarket Sales（1,000筆）- 開始使用真實資料**
```
【為什麼現在導入真實資料？】
- 學完基礎語法，需要實際應用
- Supermarket資料簡單易懂（就像超市購物明細）
- 1000筆剛好：不會太少無聊，不會太多嚇人
```

#### 2-1 認識 DataFrame：數據的表格化（20分鐘）
```
【概念講解】
DataFrame = Excel 表格的 Python 版本
- 行（Row）：一筆記錄
- 列（Column）：一個欄位
- 索引（Index）：資料的標籤

【基本操作概念】
- 讀取：從 CSV/Excel 載入數據
- 查看：顯示前幾筆、基本資訊
- 選取：挑選特定欄位或列

【Prompt 模板】
"請用 pandas 讀取 [檔案名稱]，
 並顯示 [基本資訊/前N筆/欄位名稱]"
```

#### 2-2 數據篩選與過濾（25分鐘）
```
【概念講解】
找出符合條件的數據
- 單一條件：銷售額 > 1000
- 多重條件：銷售額 > 1000 且 地區 = '台北'
- 範圍條件：日期在某區間內

【商業應用】
- 找出 VIP 客戶
- 篩選熱銷產品
- 定位問題訂單

【Prompt 模板】
"從資料中篩選出符合以下條件的記錄：
 [條件1] 且/或 [條件2]"
```

#### 2-3 數據聚合與分組（25分鐘）
```
【概念講解】
GroupBy = 分類統計
- 按類別分組
- 計算統計值（總和、平均、計數）

【商業應用】
- 各地區銷售總額
- 各產品類別平均單價
- 各客戶購買次數

【Prompt 模板】
"請按照 [分組欄位] 分組，
 計算每組的 [統計指標]"
```

#### 2-4 數據合併與連接（20分鐘）
```
【概念講解】
把多個表格組合起來
- 縱向合併：堆疊相同結構的數據
- 橫向合併：連接相關的表格

【商業應用】
- 合併各月份銷售數據
- 連接客戶資料與訂單資料
- 整合產品資訊與庫存數據

【Prompt 模板】
"請將 [表格1] 和 [表格2]
 根據 [關聯欄位] 進行合併"
```

---

### Module 3：資料品質與處理（60分鐘）13:00-14:00
📁 **資料集：Supermarket Sales（繼續使用）- 清洗和處理實作**

#### 3-1 資料品質檢查（20分鐘）
```
【檢查項目】
1. 完整性檢查
   - 空值數量與分布
   - 必填欄位的完整度

2. 一致性檢查
   - 資料格式是否統一
   - 單位是否一致

3. 合理性檢查
   - 數值範圍是否合理
   - 日期是否在預期範圍

【Prompt 模板】
"請檢查資料品質，包含：
 1. 每個欄位的缺失值數量
 2. 數值欄位的異常值
 3. 資料分布的基本統計"
```

#### 3-2 缺失值處理策略（20分鐘）
```
【處理方法】
1. 刪除法
   - 整列刪除：缺失太多的記錄
   - 整欄刪除：缺失率過高的欄位

2. 填補法
   - 固定值填補：用 0、"未知" 等
   - 統計值填補：平均值、中位數、眾數
   - 前向/後向填補：用前一筆或後一筆的值

【決策框架】
缺失率 < 5% → 簡單填補或刪除
缺失率 5-20% → 根據業務邏輯填補
缺失率 > 20% → 考慮放棄該欄位

【Prompt 模板】
"資料中 [欄位名] 有 X% 缺失值，
 請用 [方法] 進行處理"
```

#### 3-3 異常值檢測與處理（20分鐘）
```
【檢測方法】
1. 統計方法
   - 3倍標準差法則
   - 四分位距（IQR）法

2. 業務邏輯
   - 年齡 > 150（不合理）
   - 折扣 > 100%（邏輯錯誤）

【處理策略】
- 確認是否為錯誤 → 修正或刪除
- 確認是否為特殊情況 → 保留並標記
- 確認影響程度 → 決定處理方式

【Prompt 模板】
"請檢測 [欄位] 的異常值，
 使用 [方法]，
 並將異常值 [處理方式]"
```

---

### Module 4：數據視覺化與圖表選用（60分鐘）14:00-15:00
📁 **資料集：Supermarket Sales（繼續使用）- 視覺化分析結果**
```
【產出成果預覽】
- 分店銷售對比圖
- 產品線業績排名
- 時間趨勢分析
- 客戶類型分析
```

#### 4-1 圖表類型與應用場景（20分鐘）
```
【圖表選用指南】

1. 比較類 - 誰最大？
   - 長條圖：比較不同類別
   - 分組長條圖：多維度比較
   應用：各產品銷量、各地區業績

2. 趨勢類 - 如何變化？
   - 折線圖：時間序列變化
   - 面積圖：累積變化
   應用：月銷售趨勢、股價走勢

3. 分布類 - 怎麼分布？
   - 直方圖：數值分布
   - 盒鬚圖：統計分布
   應用：客戶年齡分布、消費金額分布

4. 關係類 - 有何關聯？
   - 散點圖：兩變數關係
   - 熱力圖：多變數相關性
   應用：價格vs銷量、各因素相關性

5. 組成類 - 佔比多少？
   - 圓餅圖：比例組成
   - 堆疊長條圖：組成變化
   應用：市場份額、成本結構

【選擇原則】
- 一個圖表一個重點
- 數據類型決定圖表類型
- 受眾決定複雜度
```

#### 4-2 Matplotlib 基礎概念（20分鐘）
```
【核心概念】
- Figure：畫布
- Axes：圖表區域
- Plot：繪圖指令

【基本元素】
- 標題（Title）
- 軸標籤（Labels）
- 圖例（Legend）
- 網格（Grid）

【Prompt 模板】
"請用 matplotlib 繪製 [圖表類型]，
 X軸是 [欄位1]，
 Y軸是 [欄位2]，
 標題是 [標題文字]"
```

#### 4-3 Seaborn 進階視覺化（20分鐘）
```
【為何用 Seaborn】
- 更美觀的預設樣式
- 更簡潔的語法
- 統計圖表支援

【特色功能】
- 自動計算統計值
- 分類變數視覺化
- 多變數關係矩陣

【Prompt 模板】
"請用 seaborn 繪製 [統計圖表類型]，
 展示 [變數關係]，
 按 [分類變數] 分組顯示"
```

---

### Module 5：數據分析流程與問題拆解（60分鐘）15:00-16:00
📁 **資料集切換：Online Retail（54萬筆）- RFM分析實戰開始**
```
【為什麼要換大數據集？】
- 展現Python的威力：Excel開54萬筆會當機，Python秒讀
- RFM分析需要足夠的交易歷史
- 讓學生體驗真實的大數據分析
- 前面建立的信心，現在可以挑戰進階

【緩解恐懼的方法】
- 先展示：講師先Demo處理54萬筆有多快
- 漸進式：先取1萬筆練習，確認邏輯對了再跑全部
- 強調：程式碼幾乎一樣，只是數據量變大
```

#### 5-1 標準數據分析流程（20分鐘）
```
【CRISP-DM 流程框架】

1. 問題理解（Business Understanding）
   - 要解決什麼商業問題？
   - 成功的標準是什麼？
   - Prompt："幫我釐清這個分析的商業目標..."

2. 數據理解（Data Understanding）
   - 有哪些數據可用？
   - 數據品質如何？
   - Prompt："探索這份數據的基本特徵..."

3. 數據準備（Data Preparation）
   - 清理、轉換、整合
   - Prompt："準備數據以進行[分析類型]..."

4. 分析建模（Modeling）
   - 選擇分析方法
   - 執行分析
   - Prompt："使用[方法]分析[目標]..."

5. 評估結果（Evaluation）
   - 結果是否合理？
   - 是否回答了問題？
   - Prompt："評估分析結果的可信度..."

6. 部署應用（Deployment）
   - 如何呈現結果？
   - 如何產生行動？
   - Prompt："將結果轉換為可行動的建議..."
```

#### 5-2 問題拆解技巧與麥肯錫思維（20分鐘）
```
【麥肯錫七步分析法】
1. 問題定義（Problem Definition）
   - 界定問題範圍
   - 明確成功標準
   - 設定時間框架

2. 問題分解（Disaggregation）
   - MECE原則：相互獨立，完全窮盡
   - 議題樹（Issue Tree）展開
   - 80/20法則：聚焦關鍵因素

3. 優先排序（Prioritization）
   - 影響力 vs 可行性矩陣
   - Quick Win識別
   - 資源配置決策

4. 分析計劃（Work Plan）
   - 數據需求清單
   - 分析方法選擇
   - 時間進度規劃

5. 關鍵分析（Critical Analysis）
   - 假說驅動（Hypothesis-driven）
   - 事實基礎（Fact-based）
   - 邏輯嚴謹（Logical rigor）

6. 綜合發現（Synthesis）
   - So What思考
   - 關鍵洞察提煉
   - 故事線構建

7. 溝通建議（Communication）
   - 金字塔原理
   - 行動導向
   - 數據支撐

【問題拆解範例 - MECE應用】
大問題：如何提升銷售額？

第一層拆解：
銷售額 = 客戶數 × 客單價 × 購買頻率

第二層拆解：
- 客戶數 = 新客獲取 + 舊客留存
- 客單價 = 商品單價 × 購買數量
- 購買頻率 = 購買週期 × 重購率

轉換為數據問題：
1. 新客戶獲取率是否下降？（獲客成本ROI）
2. 舊客戶流失率是否上升？（群組留存分析）
3. 平均客單價趨勢如何？（價格敏感度測試）
4. 購買頻率分布如何？（RFM分群）

【邏輯樹（Logic Tree）構建】
```
         提升銷售額
              |
    __________|__________
    |         |         |
  增加客戶  提高客單價  提升頻率
    |         |         |
  __|__     __|__     __|__
  |   |     |   |     |   |
新客 舊客  單價 數量  週期 重購
```

【假說驅動分析】
1. 形成初步假說
   "銷售下降主要因為新客獲取成本上升"
2. 設計驗證方法
   "分析CAC趨勢和轉換率變化"
3. 收集支撐數據
   "過去6個月的廣告支出和新客數"
4. 得出結論
   "確認/否定假說，調整策略"

【Prompt 模板】
"使用MECE原則將[業務問題]拆解為互不重疊、完全窮盡的子問題，
並建立邏輯樹結構"
```

#### 5-3 從分析到洞察（20分鐘）
```
【洞察挖掘框架】

1. What - 發生了什麼？
   - 描述現象
   - Prompt："數據顯示了什麼模式？"

2. So What - 這代表什麼？
   - 解釋意義
   - Prompt："這個發現對業務意味著什麼？"

3. Now What - 該做什麼？
   - 行動建議
   - Prompt："基於分析結果，建議採取什麼行動？"

【洞察品質檢核】
✓ 可行動性：能轉化為具體行動
✓ 相關性：與業務目標相關
✓ 新穎性：提供新的視角
✓ 可驗證性：能被數據支持
```

---

### Module 6：Vibe Coding 工具與 Prompt 工程（60分鐘）16:00-17:00
📁 **資料集：Online Retail（繼續使用）- 用AI處理大數據**
```
【AI + 大數據的威力展示】
- Prompt：「幫我分析這54萬筆數據的RFM」
- 展示AI如何快速生成複雜的分析程式碼
- 學生體驗：從恐懼到驚嘆
```

#### 6-1 主流 AI Coding 工具介紹（20分鐘）
```
【工具生態系】

1. 對話型 AI
   - ChatGPT：全能型助手
   - Claude：深度分析專家
   - Gemini：Google 生態整合

2. IDE 整合型
   - GitHub Copilot：程式碼自動完成
   - Cursor：AI 原生編輯器
   - Replit：線上協作環境

3. 專門型工具
   - DataCamp Workspace：數據分析特化
   - Jupyter AI：筆記本增強
   - Notable：自然語言查詢

【選擇建議】
初學者：ChatGPT/Claude + Jupyter
進階者：Cursor/Copilot + 本地環境
團隊協作：Replit/DataCamp
```

#### 6-2 Prompt 思維轉換（20分鐘）
```
【從想法到 Prompt 的轉換】

思維層次：
1. 目標層：我想要什麼結果？
2. 數據層：我有什麼數據？
3. 方法層：用什麼方法分析？
4. 輸出層：如何呈現結果？

【Prompt 公式】
背景 + 任務 + 數據 + 要求 + 輸出格式

範例：
"我是一個電商分析師（背景），
想要分析客戶購買行為（任務），
我有一份包含10萬筆訂單的數據，包含客戶ID、購買時間、金額等欄位（數據），
請幫我做RFM分析（要求），
並產出客戶分群結果和視覺化圖表（輸出）"

【迭代優化】
初版 → 執行 → 調整 → 再執行
- 太籠統 → 加入具體細節
- 錯誤多 → 分步驟執行
- 不符預期 → 提供範例
```

#### 6-3 實戰 Prompt 模板庫（20分鐘）
```
【數據載入模板】
"請幫我載入 [檔案類型] 檔案 [檔案名稱]，
檔案位於 [路徑]，
[特殊編碼/分隔符說明]，
並顯示基本資訊"

【數據清理模板】
"這份數據有以下問題：
1. [問題1描述]
2. [問題2描述]
請依序處理這些問題，並說明處理方式"

【分析執行模板】
"請對 [數據名稱] 執行 [分析類型]：
- 主要分析變數：[變數列表]
- 分組依據：[分組變數]
- 時間範圍：[起始-結束]
產出 [輸出要求]"

【視覺化模板】
"請繪製 [圖表類型] 來展示 [分析目的]：
- 數據來源：[數據框名稱]
- X軸：[變數]，標籤：[標籤文字]
- Y軸：[變數]，標籤：[標籤文字]
- 標題：[標題文字]
- 顏色/分組：[分類變數]"

【報告生成模板】
"基於以上分析結果，請產出報告：
1. 執行摘要（3-5個要點）
2. 關鍵發現（具體數據支撐）
3. 視覺化圖表（已產生）
4. 結論與建議（可行動的）"
```

---

### Module 7：報告產出與工具整合（30分鐘）17:00-17:30
📁 **資料集：兩個資料集的分析成果整合**
```
【最終產出】
- Supermarket：基礎銷售分析儀表板
- Online Retail：RFM客戶分群系統
- 整合報告：從小數據到大數據的分析之旅
```

#### 7-1 分析報告架構（15分鐘）
```
【標準報告架構】

1. Executive Summary
   - 一頁總結
   - 關鍵數字
   - 主要發現
   - 核心建議

2. 分析背景
   - 問題定義
   - 數據範圍
   - 分析方法

3. 詳細發現
   - 數據故事
   - 支撐圖表
   - 統計證據

4. 洞察與建議
   - So What
   - Now What
   - Next Steps

5. 附錄
   - 技術細節
   - 完整數據
   - 方法說明

【Prompt 模板】
"請將分析結果整理成商業報告格式，
包含摘要、發現、建議三個部分"
```

#### 7-2 跨工具整合（15分鐘）
```
【工具串連工作流】

Python 分析 → NotebookLM 整合 → 心智圖呈現

1. Python/Pandas：數據處理與分析
   輸出：CSV結果、圖表PNG

2. NotebookLM：知識整合
   - 上傳分析結果
   - 結合領域知識
   - 產生深度洞察

3. 心智圖工具：視覺化呈現
   - Xmind/Miro
   - 結構化展示
   - 便於討論

【自動化工作流 Prompt】
"請幫我將分析結果：
1. 匯出為CSV和圖表
2. 產生Markdown格式報告
3. 準備匯入其他工具的格式"
```

---

## 📊 數據分析專案檢核清單（Check List）

### 接到分析題目時的系統化流程
```
【Phase 1：問題理解】
□ 明確業務目標和成功指標
□ 了解利害關係人期望
□ 確認時間和資源限制
□ 定義分析範圍和邊界
□ 識別潛在風險和假設

【Phase 2：數據評估】
□ 盤點可用數據源
□ 評估數據品質（完整性、準確性、時效性）
□ 確認數據存取權限
□ 估算數據量和處理需求
□ 識別數據缺口

【Phase 3：方法設計】
□ 選擇適當的分析類型（描述/診斷/預測/規範）
□ 設計分析框架（MECE拆解）
□ 制定假說清單
□ 選擇統計方法和模型
□ 規劃驗證方式

【Phase 4：執行分析】
□ 數據提取和整合
□ 數據清理和轉換
□ 探索性數據分析（EDA）
□ 執行核心分析
□ 結果驗證和敏感度分析

【Phase 5：洞察提煉】
□ 識別關鍵發現
□ 進行So What測試
□ 連結業務含義
□ 形成可行動建議
□ 評估影響和風險

【Phase 6：成果交付】
□ 構建故事線
□ 準備視覺化材料
□ 撰寫執行摘要
□ 設計互動儀表板
□ 規劃後續追蹤機制

【Prompt 模板】
"我收到一個關於[分析主題]的任務，
請幫我用上述檢核清單評估專案完整性，
並識別可能遺漏的關鍵步驟"
```

## 🎓 數據分析師學習生命週期

### 從初學者到資料科學家的進階路徑
```
【Level 1：數據素養階段（0-6個月）】
核心能力：
- Excel 基礎操作
- 基本統計概念
- 簡單圖表製作
- SQL 查詢基礎

學習重點：
- 理解數據類型
- 學會提出好問題
- 培養數據思維
- 熟悉業務邏輯

產出能力：
- 基礎報表
- 簡單儀表板
- 數據品質報告

【Level 2：分析師階段（6-18個月）】
核心能力：
- Python/R 程式設計
- 統計推論和假設檢定
- 進階SQL（窗口函數、CTE）
- 數據視覺化工具（Tableau/PowerBI）

學習重點：
- A/B測試設計
- 相關性vs因果性
- 時間序列分析
- 客戶分群技術

產出能力：
- 業務洞察報告
- 預測模型原型
- 自動化報表系統

【Level 3：進階分析師（18-36個月）】
核心能力：
- 機器學習基礎
- 特徵工程
- 模型評估和優化
- 大數據工具（Spark）

學習重點：
- 監督/非監督學習
- 模型解釋性
- 實驗設計
- 因果推斷

產出能力：
- 端到端ML專案
- 推薦系統
- 預測模型部署

【Level 4：資料科學家（3年+）】
核心能力：
- 深度學習
- 自然語言處理
- 電腦視覺
- 強化學習

學習重點：
- 神經網絡架構
- 模型服務化
- MLOps實踐
- 研究方法論

產出能力：
- AI產品開發
- 創新算法研究
- 技術團隊領導
```

### 持續學習資源矩陣
```
【基礎建設】
- 數學統計：Khan Academy、3Blue1Brown
- 程式設計：Codecademy、LeetCode
- SQL練習：HackerRank、SQLZoo

【專業深化】
- 機器學習：Coursera ML Course、Fast.ai
- 數據視覺化：Storytelling with Data
- 商業分析：Google Data Analytics Certificate

【實戰練習】
- Kaggle競賽：真實問題、社群學習
- GitHub專案：建立作品集
- 開源貢獻：參與真實項目

【知識更新】
- 論文閱讀：arXiv、Papers with Code
- 技術部落格：Towards Data Science、Analytics Vidhya
- 播客收聽：Data Skeptic、Linear Digressions

【認證路徑】
- 入門：Google Data Analytics、IBM Data Science
- 進階：AWS ML Specialty、Azure Data Scientist
- 專業：CFA（金融）、SAS（統計）
```

### 不同領域的專業化方向
```
【行業垂直專業化】
1. 金融數據分析
   - 風險建模、詐欺檢測
   - 量化交易、信用評分
   - Required：金融知識、時間序列

2. 行銷數據分析
   - 客戶生命週期、歸因模型
   - A/B測試、個性化推薦
   - Required：消費心理、實驗設計

3. 醫療數據分析
   - 臨床試驗、疾病預測
   - 醫療影像、基因組學
   - Required：醫學統計、倫理規範

4. 供應鏈分析
   - 需求預測、庫存優化
   - 路徑規劃、風險管理
   - Required：運籌學、優化理論

【技術橫向專業化】
- 大數據工程師：Focus on Scale
- ML工程師：Focus on Production
- 分析工程師：Focus on Pipeline
- 決策科學家：Focus on Optimization
```

## 💡 教學小結與提醒

### 核心理念再強調
```
記住：你不是要成為程式設計師
      而是要成為懂得運用AI的分析師

1. 概念理解 > 語法記憶
   - 知道「能做什麼」比「怎麼做」重要
   - AI 會幫你處理語法細節

2. 問對問題 > 寫對程式
   - 好的 Prompt = 清楚的思維
   - 拆解問題的能力最關鍵

3. 迭代改進 > 一次完美
   - 與 AI 對話是個迭代過程
   - 每次執行都是學習機會
```

### 學習資源與後續
```
【練習資源】
- Kaggle Learn：免費數據分析課程
- Google Colab：免費雲端練習環境
- 公開數據集：政府開放資料平台

【進階學習路徑】
基礎：Excel 思維 → Python 思維
進階：描述性分析 → 預測性分析
專業：通用分析 → 領域專門（金融/行銷/營運）

【社群資源】
- PyData Taiwan
- Taiwan R User Group
- Data Science Meetup
```

### 作業與實戰
```
【課後作業】
使用提供的銷售數據集，完成：
1. 數據品質報告
2. 月銷售趨勢分析
3. 產品類別表現比較
4. 客戶區隔分析
5. 一頁式洞察報告

【評量標準】
- 分析邏輯正確（40%）
- Prompt 使用恰當（30%）
- 視覺化清晰（20%）
- 洞察有價值（10%）
```

---

## 📝 Prompt 模板速查表（學員講義）

### 基礎操作類
```python
# 讀取數據
"請讀取 [檔案名稱.csv]，顯示前5筆資料和基本統計資訊"

# 數據概覽
"請分析這份數據的：
1. 資料筆數和欄位數
2. 各欄位的資料類型
3. 缺失值統計
4. 基本統計描述"

# 數據篩選
"請篩選出 [欄位名稱] [條件] 的所有資料"

# 數據分組
"請按 [欄位A] 分組，計算每組的 [欄位B] 的 [統計量]"
```

### 分析執行類
```python
# 相關性分析
"請計算所有數值欄位之間的相關係數，並用熱力圖呈現"

# 趨勢分析
"請分析 [時間欄位] 對 [數值欄位] 的變化趨勢，並繪製折線圖"

# 分布分析
"請分析 [欄位名稱] 的數值分布，包含直方圖和統計描述"

# 比較分析
"請比較不同 [類別欄位] 的 [數值欄位] 差異，用箱形圖呈現"
```

### 視覺化類
```python
# 基本圖表
"請繪製 [圖表類型]：
- X軸：[欄位]
- Y軸：[欄位]
- 標題：[文字]
- 加入數值標籤"

# 多子圖
"請創建 2×2 的子圖，分別顯示：
1. [圖表1描述]
2. [圖表2描述]
3. [圖表3描述]
4. [圖表4描述]"

# 互動式圖表
"請用 plotly 創建互動式 [圖表類型]，
滑鼠懸停顯示 [詳細資訊]"
```

### 報告產出類
```python
# 分析總結
"根據以上分析，請總結：
1. 三個關鍵發現
2. 數據支撐證據
3. 商業含義"

# 行動建議
"基於分析結果，請提供：
1. 立即可執行的 3 個行動
2. 預期效果
3. 風險提醒"
```

---

*最後更新：2024.12*
*版本：Vibe Coding 數據分析工作坊 v1.0*